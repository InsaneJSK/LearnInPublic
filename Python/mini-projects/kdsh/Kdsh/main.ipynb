{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>book_name</th>\n",
       "      <th>char</th>\n",
       "      <th>caption</th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46</td>\n",
       "      <td>In Search of the Castaways</td>\n",
       "      <td>Thalcave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Thalcave’s people faded as colonists advanced;...</td>\n",
       "      <td>consistent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                   book_name      char caption  \\\n",
       "0  46  In Search of the Castaways  Thalcave     NaN   \n",
       "\n",
       "                                             content       label  \n",
       "0  Thalcave’s people faded as colonists advanced;...  consistent  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "\n",
    "print(train.shape)\n",
    "train.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def split_claims(text):\n",
    "    parts = re.split(r\"[.;]\\s+| and | but | however \", text, flags=re.IGNORECASE)\n",
    "    claims = []\n",
    "\n",
    "    for p in parts:\n",
    "        p = p.strip()\n",
    "        if len(p) > 20:   # ignore very small fragments\n",
    "            claims.append(p)\n",
    "\n",
    "    return claims\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping between book names in CSV and actual files\n",
    "BOOK_PATHS = {\n",
    "    \"The Count of Monte Cristo\": \"books/The Count of Monte Cristo.txt\",\n",
    "    \"In Search of the Castaways\": \"books/In search of the castaways.txt\"\n",
    "}\n",
    "\n",
    "def load_book(book_name):\n",
    "    \"\"\"\n",
    "    Given a book name from the CSV, load and return the full book text.\n",
    "    \"\"\"\n",
    "    path = BOOK_PATHS[book_name]\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_book(book_text):\n",
    " \n",
    "    raw_paragraphs = book_text.split(\"\\n\\n\")\n",
    "\n",
    "    chunks = []\n",
    "    idx = 0\n",
    "\n",
    "    for p in raw_paragraphs:\n",
    "        p = p.strip()\n",
    "        if len(p) < 100:  \n",
    "            continue\n",
    "\n",
    "        chunks.append({\n",
    "            \"idx\": idx,\n",
    "            \"text\": p\n",
    "        })\n",
    "        idx += 1\n",
    "\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords(claim):\n",
    "    \"\"\"\n",
    "    Take a claim sentence and extract important words.\n",
    "    We ignore short words to avoid noise.\n",
    "    \"\"\"\n",
    "    words = claim.lower().split()\n",
    "    keywords = [w for w in words if len(w) >= 5]\n",
    "    return keywords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_chunks(chunks, character, claim):\n",
    "    \"\"\"\n",
    "    Return book chunks that mention the character\n",
    "    or contain important keywords from the claim.\n",
    "    \"\"\"\n",
    "    keywords = extract_keywords(claim)\n",
    "    character = character.lower()\n",
    "\n",
    "    relevant = []\n",
    "\n",
    "    for c in chunks:\n",
    "        text = c[\"text\"].lower()\n",
    "\n",
    "        if character in text:\n",
    "            relevant.append(c)\n",
    "        else:\n",
    "            for kw in keywords:\n",
    "                if kw in text:\n",
    "                    relevant.append(c)\n",
    "                    break\n",
    "\n",
    "    return relevant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABSOLUTE_WORDS = [\n",
    "    \"never\",\n",
    "    \"always\",\n",
    "    \"only\",\n",
    "    \"since childhood\",\n",
    "    \"from birth\",\n",
    "    \"throughout his life\",\n",
    "    \"throughout her life\"\n",
    "]\n",
    "\n",
    "EVENT_KEYWORDS = [\n",
    "    \"arrested\", \"re-arrested\", \"imprisoned\", \"released\",\n",
    "    \"escaped\", \"escape\", \"died\", \"death\", \"killed\",\n",
    "    \"sentenced\", \"confined\"\n",
    "]\n",
    "\n",
    "TIME_MARKERS = [\n",
    "    \"again\", \"this time\", \"for life\"\n",
    "]\n",
    "\n",
    "def is_absolute_claim(claim):\n",
    "    claim = claim.lower()\n",
    "    for w in ABSOLUTE_WORDS:\n",
    "        if w in claim:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def is_event_claim(claim):\n",
    "    c = claim.lower()\n",
    "    has_event = any(k in c for k in EVENT_KEYWORDS)\n",
    "    has_time = any(t in c for t in TIME_MARKERS) or any(ch.isdigit() for ch in c)\n",
    "    return has_event and has_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_hard_contradiction(claim, relevant_chunks):\n",
    "    \"\"\"\n",
    "    Return True if we see a clear contradiction.\n",
    "    \"\"\"\n",
    "    if not is_absolute_claim(claim):\n",
    "        return False\n",
    "\n",
    "    for c in relevant_chunks:\n",
    "        text = c[\"text\"].lower()\n",
    "\n",
    "        # very simple signals of change or later action\n",
    "        if \"later\" in text or \"years later\" in text or \"afterward\" in text:\n",
    "            return True\n",
    "\n",
    "        if \"returned\" in text and \"never returned\" in claim.lower():\n",
    "            return True\n",
    "\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_event_contradiction(claim, relevant_chunks):\n",
    "    \"\"\"\n",
    "    Return True if the book strongly suggests\n",
    "    an incompatible event history.\n",
    "    \"\"\"\n",
    "    if not is_event_claim(claim):\n",
    "        return False\n",
    "\n",
    "    c = claim.lower()\n",
    "\n",
    "    for ch in relevant_chunks:\n",
    "        text = ch[\"text\"].lower()\n",
    "\n",
    "        # If claim implies a new arrest, but book says already imprisoned\n",
    "        if \"re-arrest\" in c or \"again\" in c:\n",
    "            if \"already imprisoned\" in text or \"had been imprisoned\" in text:\n",
    "                return True\n",
    "            if \"never released\" in text:\n",
    "                return True\n",
    "\n",
    "        # If claim says 'for life', but book mentions death shortly after\n",
    "        if \"for life\" in c:\n",
    "            if \"died\" in text or \"death\" in text:\n",
    "                return True\n",
    "\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_backstory(row):\n",
    "    claims = split_claims(row[\"content\"])\n",
    "    book_text = load_book(row[\"book_name\"])\n",
    "    chunks = chunk_book(book_text)\n",
    "\n",
    "    for claim in claims:\n",
    "        relevant_chunks = retrieve_chunks(\n",
    "            chunks=chunks,\n",
    "            character=row[\"char\"],\n",
    "            claim=claim\n",
    "        )\n",
    "\n",
    "        # Rule 1: Absolute contradiction\n",
    "        if has_hard_contradiction(claim, relevant_chunks):\n",
    "            return 0\n",
    "\n",
    "        # Rule 2: Event-existence contradiction (NEW)\n",
    "        if has_event_contradiction(claim, relevant_chunks):\n",
    "            return 0\n",
    "\n",
    "    return 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_claims(claims):\n",
    "    clean = []\n",
    "\n",
    "    for c in claims:\n",
    "        c = c.strip()\n",
    "\n",
    "        # Reject very short fragments\n",
    "        if len(c) < 25:\n",
    "            continue\n",
    "\n",
    "        # Reject speculation / soft language\n",
    "        if any(w in c.lower() for w in [\n",
    "            \"might\", \"could\", \"possibly\", \"perhaps\", \"likely\"\n",
    "        ]):\n",
    "            continue\n",
    "\n",
    "        # Reject explanations\n",
    "        if any(w in c.lower() for w in [\n",
    "            \"because\", \"therefore\", \"suggests that\"\n",
    "        ]):\n",
    "            continue\n",
    "\n",
    "        clean.append(c)\n",
    "\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_claims_safe(backstory):\n",
    "    # Try Gemini first\n",
    "    claims = gemini_split_claims(backstory)\n",
    "\n",
    "    if claims:\n",
    "        claims = sanitize_claims(claims)\n",
    "\n",
    "        # Safety check: must not reduce info too much\n",
    "        if len(claims) >= 1:\n",
    "            return claims\n",
    "\n",
    "    # Fallback to regex splitter\n",
    "    return split_claims(backstory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLAIM:\n",
      "Thalcave’s people faded as colonists advanced\n",
      "\n",
      "IS ABSOLUTE?: False\n",
      "\n",
      "HARD CONTRADICTION?: False\n"
     ]
    }
   ],
   "source": [
    "row = train.iloc[0]\n",
    "claims = split_claims(row[\"content\"])\n",
    "claim = claims[0]\n",
    "\n",
    "relevant_chunks = retrieve_chunks(\n",
    "    chunks=chunk_book(load_book(row[\"book_name\"])),\n",
    "    character=row[\"char\"],\n",
    "    claim=claim\n",
    ")\n",
    "\n",
    "print(\"CLAIM:\")\n",
    "print(claim)\n",
    "\n",
    "print(\"\\nIS ABSOLUTE?:\", is_absolute_claim(claim))\n",
    "\n",
    "print(\"\\nHARD CONTRADICTION?:\",\n",
    "      has_hard_contradiction(claim, relevant_chunks))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL: 80\n",
      "CORRECT: 51\n",
      "ACCURACY: 0.6375\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = len(train)\n",
    "\n",
    "for _, row in train.iterrows():\n",
    "    pred = predict_backstory(row)\n",
    "    gold = 1 if row[\"label\"] == \"consistent\" else 0\n",
    "\n",
    "    if pred == gold:\n",
    "        correct += 1\n",
    "\n",
    "accuracy = correct / total\n",
    "print(\"TOTAL:\", total)\n",
    "print(\"CORRECT:\", correct)\n",
    "print(\"ACCURACY:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL: 80\n",
      "CORRECT: 51\n",
      "ACCURACY: 0.6375\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = len(train)\n",
    "\n",
    "for _, row in train.iterrows():\n",
    "    pred = predict_backstory(row)\n",
    "    gold = 1 if row[\"label\"] == \"consistent\" else 0\n",
    "\n",
    "    if pred == gold:\n",
    "        correct += 1\n",
    "\n",
    "accuracy = correct / total\n",
    "print(\"TOTAL:\", total)\n",
    "print(\"CORRECT:\", correct)\n",
    "print(\"ACCURACY:\", accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
