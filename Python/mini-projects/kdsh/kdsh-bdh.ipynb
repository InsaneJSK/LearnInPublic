{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "editable": false,
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "!pip install sentence-transformers transformers tqdm --q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kaggle/input/d/insanejsk/kdsh-books/Dataset/train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#2\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m train = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/kaggle/input/d/insanejsk/kdsh-books/Dataset/train.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m test = pd.read_csv(\u001b[33m\"\u001b[39m\u001b[33m/kaggle/input/d/insanejsk/kdsh-books/Dataset/test.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m BOOKS_PATH = \u001b[33m\"\u001b[39m\u001b[33m/kaggle/input/d/insanejsk/kdsh-books/Dataset/Books\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\JSK\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\JSK\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\JSK\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\JSK\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\JSK\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/kaggle/input/d/insanejsk/kdsh-books/Dataset/train.csv'"
     ]
    }
   ],
   "source": [
    "#2\n",
    "import pandas as pd\n",
    "train = pd.read_csv(\"/kaggle/input/d/insanejsk/kdsh-books/Dataset/train.csv\")\n",
    "test = pd.read_csv(\"/kaggle/input/d/insanejsk/kdsh-books/Dataset/test.csv\")\n",
    "BOOKS_PATH = \"/kaggle/input/d/insanejsk/kdsh-books/Dataset/Books\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#3\n",
    "def normalize_book_name(name):\n",
    "    return name.strip().lower()  # lowercase + strip spaces\n",
    "\n",
    "train[\"book_name\"] = train[\"book_name\"].apply(normalize_book_name)\n",
    "test[\"book_name\"] = test[\"book_name\"].apply(normalize_book_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#4\n",
    "import glob, os\n",
    "book_texts = {}\n",
    "for path in glob.glob(os.path.join(BOOKS_PATH, \"*.txt\")):\n",
    "    name = os.path.basename(path).replace(\".txt\",\"\").strip()\n",
    "    norm_name = name.lower()\n",
    "    with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        book_texts[norm_name] = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#5\n",
    "CHUNK_SIZE=800\n",
    "CHUNK_OVERLAP=200\n",
    "\n",
    "def chunk_text(text, chunk_size=CHUNK_SIZE, overlap=CHUNK_OVERLAP):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    i = 0\n",
    "    while i < len(words):\n",
    "        chunk = \" \".join(words[i:i+chunk_size])\n",
    "        chunks.append(chunk)\n",
    "        i += chunk_size - overlap\n",
    "    return chunks\n",
    "\n",
    "book_chunks = {name.lower(): chunk_text(txt) for name, txt in book_texts.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#6\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "embedder = SentenceTransformer(\"multi-qa-mpnet-base-dot-v1\", device=device)\n",
    "\n",
    "embedded_books = {name.lower(): embedder.encode(chunks, convert_to_tensor=True) for name, chunks in book_chunks.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "embedded_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#7\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cross-encoder/nli-deberta-base\")\n",
    "nli_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"cross-encoder/nli-deberta-base\"\n",
    ").to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def nli_score(premise, hypothesis):\n",
    "    inputs = tokenizer(premise, hypothesis, return_tensors=\"pt\", truncation=True, padding=True).to(nli_model.device)\n",
    "    with torch.no_grad():\n",
    "        logits = nli_model(**inputs).logits\n",
    "    probs = torch.softmax(logits, dim=-1).cpu().numpy()[0]\n",
    "    return {\n",
    "        \"contradiction\": probs[0],\n",
    "        \"neutral\": probs[1],\n",
    "        \"entailment\": probs[2]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import util\n",
    "import numpy as np\n",
    "def score_backstory_weighted(book_name, backstory_text, top_k=10, sim_threshold=0.5, alpha=1.0, beta=1.0):\n",
    "    norm_book = book_name.strip().lower()\n",
    "    memory = {\"entail\": [], \"contradict\": []}\n",
    "    evidence_chunks = []\n",
    "\n",
    "    book_embs = embedded_books[norm_book]\n",
    "    book_chunks_list = book_chunks[norm_book]\n",
    "\n",
    "    back_emb = embedder.encode(backstory_text, convert_to_tensor=True)\n",
    "    sims = util.cos_sim(back_emb, book_embs)[0]\n",
    "    top_idx = torch.topk(sims, k=top_k).indices.cpu().numpy()\n",
    "\n",
    "    for idx in top_idx:\n",
    "        if sims[idx] < sim_threshold:\n",
    "            continue\n",
    "        chunk = book_chunks_list[idx]\n",
    "        nli = nli_score(chunk, backstory_text)\n",
    "        \n",
    "        # BDH-style selective update\n",
    "        if nli[\"entailment\"] > 0.7:\n",
    "            memory[\"entail\"].append(nli[\"entailment\"])\n",
    "            evidence_chunks.append(chunk)\n",
    "        if nli[\"contradiction\"] > 0.6:\n",
    "            memory[\"contradict\"].append(nli[\"contradiction\"])\n",
    "\n",
    "    entail_mean = np.mean(memory[\"entail\"]) if memory[\"entail\"] else 0.0\n",
    "    contradict_mean = np.mean(memory[\"contradict\"]) if memory[\"contradict\"] else 0.0\n",
    "\n",
    "    score = alpha * entail_mean - beta * contradict_mean\n",
    "    pred = 1 if score > 0 else 0\n",
    "    return pred, score, evidence_chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "train_preds = []\n",
    "for _, row in tqdm(train.iterrows(), total=len(train)):\n",
    "    p, e, c = score_backstory(row[\"book_name\"], row[\"content\"])\n",
    "    train_preds.append({\"id\": row[\"id\"], \"prediction\": p, \"entail\": e, \"contradict\": c})\n",
    "\n",
    "train_results = pd.DataFrame(train_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2026-01-11T17:00:22.510194Z",
     "iopub.status.busy": "2026-01-11T17:00:22.509868Z",
     "iopub.status.idle": "2026-01-11T17:00:22.516535Z",
     "shell.execute_reply": "2026-01-11T17:00:22.515399Z",
     "shell.execute_reply.started": "2026-01-11T17:00:22.510165Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_56/3497990418.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label_bin\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"consistent\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"contradict\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_results' is not defined"
     ]
    }
   ],
   "source": [
    "train_results = train_results.merge(train[[\"id\",\"label\"]], on=\"id\")\n",
    "train_results[\"label_bin\"] = train_results[\"label\"].map({\"consistent\":1, \"contradict\":0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2026-01-11T08:00:16.353146Z",
     "iopub.status.busy": "2026-01-11T08:00:16.352866Z",
     "iopub.status.idle": "2026-01-11T08:00:16.372102Z",
     "shell.execute_reply": "2026-01-11T08:00:16.371387Z",
     "shell.execute_reply.started": "2026-01-11T08:00:16.353113Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 0.4875\n",
      "Precision      : 0.6250\n",
      "Recall         : 0.4902\n",
      "F1-score       : 0.5495\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "y_true = train_results[\"label_bin\"].values\n",
    "y_pred = train_results[\"prediction\"].values\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "prec = precision_score(y_true, y_pred)\n",
    "rec = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "print(f\"Train Accuracy : {acc:.4f}\")\n",
    "print(f\"Precision      : {prec:.4f}\")\n",
    "print(f\"Recall         : {rec:.4f}\")\n",
    "print(f\"F1-score       : {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2026-01-11T07:53:07.150164Z",
     "iopub.status.busy": "2026-01-11T07:53:07.149836Z",
     "iopub.status.idle": "2026-01-11T07:53:07.278929Z",
     "shell.execute_reply": "2026-01-11T07:53:07.278254Z",
     "shell.execute_reply.started": "2026-01-11T07:53:07.150129Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"contradict\",\"consistent\"], yticklabels=[\"contradict\",\"consistent\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2026-01-11T07:55:04.352742Z",
     "iopub.status.busy": "2026-01-11T07:55:04.352040Z",
     "iopub.status.idle": "2026-01-11T07:55:04.359772Z",
     "shell.execute_reply": "2026-01-11T07:55:04.359003Z",
     "shell.execute_reply.started": "2026-01-11T07:55:04.352707Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14, 15],\n",
       "       [26, 25]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2026-01-11T17:01:30.032310Z",
     "iopub.status.busy": "2026-01-11T17:01:30.032017Z",
     "iopub.status.idle": "2026-01-11T17:01:30.043160Z",
     "shell.execute_reply": "2026-01-11T17:01:30.042394Z",
     "shell.execute_reply.started": "2026-01-11T17:01:30.032273Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m f1_score, accuracy_score\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# map train labels to binary\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m train[\u001b[33m\"\u001b[39m\u001b[33mlabel_bin\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mtrain\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m\"\u001b[39m].map({\u001b[33m\"\u001b[39m\u001b[33mconsistent\u001b[39m\u001b[33m\"\u001b[39m:\u001b[32m1\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mcontradict\u001b[39m\u001b[33m\"\u001b[39m:\u001b[32m0\u001b[39m})\n\u001b[32m     10\u001b[39m y_true = train[\u001b[33m\"\u001b[39m\u001b[33mlabel_bin\u001b[39m\u001b[33m\"\u001b[39m].values\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# parameter grid ranges\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "#8\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "# map train labels to binary\n",
    "train[\"label_bin\"] = train[\"label\"].map({\"consistent\":1,\"contradict\":0})\n",
    "y_true = train[\"label_bin\"].values\n",
    "\n",
    "# parameter grid ranges\n",
    "top_k_choices = [5,7,10,12,15]\n",
    "sim_threshold_range = (0.4, 0.6)\n",
    "alpha_range = (0.5, 1.5)\n",
    "beta_range = (0.5, 1.5)\n",
    "\n",
    "best_score = 0\n",
    "best_params = {}\n",
    "\n",
    "# cache NLI to avoid recomputation\n",
    "nli_cache = {}\n",
    "\n",
    "def get_nli(chunk, backstory):\n",
    "    key = (chunk, backstory)\n",
    "    if key not in nli_cache:\n",
    "        nli_cache[key] = nli_score(chunk, backstory)\n",
    "    return nli_cache[key]\n",
    "\n",
    "# def score_backstory_weighted(book_name, backstory_text, top_k, sim_threshold, alpha, beta):\n",
    "#     norm_book = book_name.strip().lower()\n",
    "#     memory = {\"entail\": [], \"contradict\": []}\n",
    "\n",
    "#     book_embs = embedded_books[norm_book]\n",
    "#     book_chunks_list = book_chunks[norm_book]\n",
    "\n",
    "#     back_emb = embedder.encode(backstory_text, convert_to_tensor=True)\n",
    "#     sims = util.cos_sim(back_emb, book_embs)[0]\n",
    "#     top_idx = torch.topk(sims, k=top_k).indices.cpu().numpy()\n",
    "\n",
    "#     for idx in top_idx:\n",
    "#         if sims[idx] < sim_threshold:\n",
    "#             continue\n",
    "#         chunk = book_chunks_list[idx]\n",
    "#         nli = get_nli(chunk, backstory_text)\n",
    "\n",
    "#         # BDH-style selective update\n",
    "#         if nli[\"entailment\"] > 0.7:\n",
    "#             memory[\"entail\"].append(nli[\"entailment\"])\n",
    "#         if nli[\"contradiction\"] > 0.6:\n",
    "#             memory[\"contradict\"].append(nli[\"contradiction\"])\n",
    "\n",
    "#     entail_mean = np.mean(memory[\"entail\"]) if memory[\"entail\"] else 0.0\n",
    "#     contradict_mean = np.mean(memory[\"contradict\"]) if memory[\"contradict\"] else 0.0\n",
    "\n",
    "#     score = alpha * entail_mean - beta * contradict_mean\n",
    "#     pred = 1 if score > 0 else 0\n",
    "#     return pred\n",
    "\n",
    "# # ------------------- K-Fold Random Search -------------------\n",
    "# n_trials = 50   # number of random parameter samples\n",
    "# n_splits = 5    # 5-fold CV\n",
    "# kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# for _ in tqdm(range(n_trials)):\n",
    "#     # randomly sample hyperparameters\n",
    "#     top_k = random.choice(top_k_choices)\n",
    "#     sim_threshold = random.uniform(*sim_threshold_range)\n",
    "#     alpha = random.uniform(*alpha_range)\n",
    "#     beta = random.uniform(*beta_range)\n",
    "\n",
    "#     fold_scores = []\n",
    "\n",
    "#     for train_idx, val_idx in kf.split(train):\n",
    "#         val_preds = []\n",
    "#         val_labels = y_true[val_idx]\n",
    "\n",
    "#         for i in val_idx:\n",
    "#             row = train.iloc[i]\n",
    "#             p = score_backstory_weighted(\n",
    "#                 row[\"book_name\"], row[\"content\"], top_k, sim_threshold, alpha, beta\n",
    "#             )\n",
    "#             val_preds.append(p)\n",
    "\n",
    "#         f1 = f1_score(val_labels, val_preds)\n",
    "#         fold_scores.append(f1)\n",
    "\n",
    "#     mean_f1 = np.mean(fold_scores)\n",
    "\n",
    "#     if mean_f1 > best_score:\n",
    "#         best_score = mean_f1\n",
    "#         best_params = {\n",
    "#             \"top_k\": top_k,\n",
    "#             \"sim_threshold\": sim_threshold,\n",
    "#             \"alpha\": alpha,\n",
    "#             \"beta\": beta,\n",
    "#             \"mean_f1\": mean_f1\n",
    "#         }\n",
    "\n",
    "# print(\"Best Random Search with CV Result:\")\n",
    "# print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2026-01-11T17:01:30.045244Z",
     "iopub.status.busy": "2026-01-11T17:01:30.045004Z",
     "iopub.status.idle": "2026-01-11T17:01:30.066029Z",
     "shell.execute_reply": "2026-01-11T17:01:30.065378Z",
     "shell.execute_reply.started": "2026-01-11T17:01:30.045222Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#9\n",
    "@torch.no_grad()\n",
    "def score_backstory_weighted(book_name, backstory_text, top_k, sim_threshold, alpha, beta):\n",
    "    norm_book = book_name.strip().lower()\n",
    "    memory = {\"entail\": [], \"contradict\": []}\n",
    "    evidence_chunks = []\n",
    "\n",
    "    book_embs = embedded_books[norm_book]\n",
    "    book_chunks_list = book_chunks[norm_book]\n",
    "\n",
    "    back_emb = embedder.encode(backstory_text, convert_to_tensor=True, device=device)\n",
    "    sims = util.cos_sim(back_emb, book_embs)[0]\n",
    "    top_idx = torch.topk(sims, k=top_k).indices.tolist()\n",
    "\n",
    "    for idx in top_idx:\n",
    "        if sims[idx].item() < sim_threshold:\n",
    "            continue\n",
    "        chunk = book_chunks_list[idx]\n",
    "        nli = get_nli(chunk, backstory_text)\n",
    "\n",
    "        # BDH-style selective update\n",
    "        if nli[\"entailment\"] > 0.7:\n",
    "            memory[\"entail\"].append(nli[\"entailment\"])\n",
    "            evidence_chunks.append(chunk)   # track rationale\n",
    "        if nli[\"contradiction\"] > 0.6:\n",
    "            memory[\"contradict\"].append(nli[\"contradiction\"])\n",
    "            evidence_chunks.append(chunk)   # track rationale\n",
    "\n",
    "    entail_mean = np.mean(memory[\"entail\"]) if memory[\"entail\"] else 0.0\n",
    "    contradict_mean = np.mean(memory[\"contradict\"]) if memory[\"contradict\"] else 0.0\n",
    "\n",
    "    score = alpha * entail_mean - beta * contradict_mean\n",
    "    pred = 1 if score > 0 else 0\n",
    "\n",
    "    return pred, score, evidence_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2026-01-11T16:58:52.561638Z",
     "iopub.status.busy": "2026-01-11T16:58:52.561275Z",
     "iopub.status.idle": "2026-01-11T16:58:52.565814Z",
     "shell.execute_reply": "2026-01-11T16:58:52.565140Z",
     "shell.execute_reply.started": "2026-01-11T16:58:52.561609Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Best Random Search with CV Result:\n",
    "#{'top_k': 15, 'sim_threshold': 0.4128825899953899, 'alpha': 1.3060216504048299, 'beta': 0.7987142657077282, 'mean_f1': np.float64(0.7612535612535613)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2026-01-11T17:18:32.129092Z",
     "iopub.status.busy": "2026-01-11T17:18:32.128502Z",
     "iopub.status.idle": "2026-01-11T17:18:33.096302Z",
     "shell.execute_reply": "2026-01-11T17:18:33.095413Z",
     "shell.execute_reply.started": "2026-01-11T17:18:32.129063Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with optimized params: top_k=15, threshold=0.41, alpha=1.31, beta=0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 80/80 [00:00<00:00, 83.93it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'label_bin'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'label_bin'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_56/3799701988.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mtrain_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label_bin\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_preds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'label_bin'"
     ]
    }
   ],
   "source": [
    "#10 -- PULKIT BHAI\n",
    "# ------------------- Run Train & Test -------------------\n",
    "\n",
    "# Use the best hyperparameters from CV\n",
    "top_k = 15\n",
    "sim_threshold = 0.4128825899953899\n",
    "alpha = 1.3060216504048299\n",
    "beta = 0.7987142657077282\n",
    "\n",
    "print(f\"Running with optimized params: top_k={top_k}, threshold={sim_threshold:.2f}, alpha={alpha:.2f}, beta={beta:.2f}\")\n",
    "\n",
    "# --------------- TRAIN METRICS ----------------\n",
    "train_preds = []\n",
    "train_evidence = []  # optional rationale\n",
    "\n",
    "for idx, row in tqdm(train.iterrows(), total=len(train)):\n",
    "    pred, score, evidence_chunks = score_backstory_weighted(\n",
    "        row[\"book_name\"], row[\"content\"], top_k, sim_threshold, alpha, beta\n",
    "    )\n",
    "    train_preds.append(pred)\n",
    "    train_evidence.append(evidence_chunks)\n",
    "\n",
    "train_preds = np.array(train_preds)\n",
    "y_true = train[\"label_bin\"].values\n",
    "\n",
    "train_acc = (train_preds == y_true).mean()\n",
    "train_f1 = f1_score(y_true, train_preds)\n",
    "\n",
    "print(f\"Train Accuracy: {train_acc:.4f}\")\n",
    "print(f\"Train F1: {train_f1:.4f}\")\n",
    "\n",
    "# Optional: add rationale column to train dataframe\n",
    "train[\"prediction\"] = train_preds\n",
    "train[\"evidence_chunks\"] = train_evidence\n",
    "\n",
    "# # --------------- TEST PREDICTIONS ----------------\n",
    "# test_preds = []\n",
    "# test_evidence = []\n",
    "\n",
    "# for idx, row in tqdm(test.iterrows(), total=len(test)):\n",
    "#     pred, score, evidence_chunks = score_backstory_weighted(\n",
    "#         row[\"book_name\"], row[\"content\"], top_k, sim_threshold, alpha, beta\n",
    "#     )\n",
    "#     test_preds.append(pred)\n",
    "#     test_evidence.append(evidence_chunks)\n",
    "\n",
    "# # convert to DataFrame for submission\n",
    "# submission = test.copy()\n",
    "# submission[\"prediction\"] = test_preds\n",
    "# submission[\"evidence_chunks\"] = test_evidence\n",
    "# submission[\"label\"] = submission[\"prediction\"].map({1:\"consistent\", 0:\"contradict\"})\n",
    "\n",
    "# # Save CSV\n",
    "# submission[[\"id\", \"label\", \"evidence_chunks\"]].to_csv(\"results.csv\", index=False)\n",
    "# print(\"results.csv ready for submission!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2026-01-11T17:02:56.805153Z",
     "iopub.status.busy": "2026-01-11T17:02:56.804836Z",
     "iopub.status.idle": "2026-01-11T17:03:00.684670Z",
     "shell.execute_reply": "2026-01-11T17:03:00.683883Z",
     "shell.execute_reply.started": "2026-01-11T17:02:56.805118Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 6)\n",
      "TOTAL: 80\n",
      "CORRECT: 51\n",
      "ACCURACY: 0.6375\n"
     ]
    }
   ],
   "source": [
    "#11\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(\"/kaggle/input/d/insanejsk/kdsh-books/Dataset/train.csv\")\n",
    "\n",
    "print(train.shape)\n",
    "train.head(1)\n",
    "\n",
    "def split_claims(text):\n",
    "    parts = re.split(r\"[.;]\\s+| and | but | however \", text, flags=re.IGNORECASE)\n",
    "    claims = []\n",
    "\n",
    "    for p in parts:\n",
    "        p = p.strip()\n",
    "        if len(p) > 20:   # ignore very small fragments\n",
    "            claims.append(p)\n",
    "\n",
    "    return claims\n",
    "\n",
    "# Mapping between book names in CSV and actual files\n",
    "BOOK_PATHS = {\n",
    "    \"The Count of Monte Cristo\": \"/kaggle/input/d/insanejsk/kdsh-books/Dataset/Books/The Count of Monte Cristo.txt\",\n",
    "    \"In Search of the Castaways\": \"/kaggle/input/d/insanejsk/kdsh-books/Dataset/Books/In search of the castaways.txt\"\n",
    "}\n",
    "\n",
    "def load_book(book_name):\n",
    "    \"\"\"\n",
    "    Given a book name from the CSV, load and return the full book text.\n",
    "    \"\"\"\n",
    "    path = BOOK_PATHS[book_name]\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return f.read()\n",
    "\n",
    "def chunk_book(book_text):\n",
    "    raw_paragraphs = book_text.split(\"\\n\\n\")\n",
    "\n",
    "    chunks = []\n",
    "    idx = 0\n",
    "\n",
    "    for p in raw_paragraphs:\n",
    "        p = p.strip()\n",
    "        if len(p) < 100:\n",
    "            continue\n",
    "\n",
    "        chunks.append({\n",
    "            \"idx\": idx,\n",
    "            \"text\": p\n",
    "        })\n",
    "        idx += 1\n",
    "\n",
    "    return chunks\n",
    "\n",
    "def extract_keywords(claim):\n",
    "    \"\"\"\n",
    "    Take a claim sentence and extract important words.\n",
    "    We ignore short words to avoid noise.\n",
    "    \"\"\"\n",
    "    words = claim.lower().split()\n",
    "    keywords = [w for w in words if len(w) >= 5]\n",
    "    return keywords\n",
    "\n",
    "def retrieve_chunks(chunks, character, claim):\n",
    "    \"\"\"\n",
    "    Return book chunks that mention the character\n",
    "    or contain important keywords from the claim.\n",
    "    \"\"\"\n",
    "    keywords = extract_keywords(claim)\n",
    "    character = character.lower()\n",
    "\n",
    "    relevant = []\n",
    "\n",
    "    for c in chunks:\n",
    "        text = c[\"text\"].lower()\n",
    "\n",
    "        if character in text:\n",
    "            relevant.append(c)\n",
    "        else:\n",
    "            for kw in keywords:\n",
    "                if kw in text:\n",
    "                    relevant.append(c)\n",
    "                    break\n",
    "\n",
    "    return relevant\n",
    "\n",
    "ABSOLUTE_WORDS = [\n",
    "    \"never\",\n",
    "    \"always\",\n",
    "    \"only\",\n",
    "    \"since childhood\",\n",
    "    \"from birth\",\n",
    "    \"throughout his life\",\n",
    "    \"throughout her life\"\n",
    "]\n",
    "\n",
    "EVENT_KEYWORDS = [\n",
    "    \"arrested\", \"re-arrested\", \"imprisoned\", \"released\",\n",
    "    \"escaped\", \"escape\", \"died\", \"death\", \"killed\",\n",
    "    \"sentenced\", \"confined\"\n",
    "]\n",
    "\n",
    "TIME_MARKERS = [\n",
    "    \"again\", \"this time\", \"for life\"\n",
    "]\n",
    "\n",
    "def is_absolute_claim(claim):\n",
    "    claim = claim.lower()\n",
    "    for w in ABSOLUTE_WORDS:\n",
    "        if w in claim:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def is_event_claim(claim):\n",
    "    c = claim.lower()\n",
    "    has_event = any(k in c for k in EVENT_KEYWORDS)\n",
    "    has_time = any(t in c for t in TIME_MARKERS) or any(ch.isdigit() for ch in c)\n",
    "    return has_event and has_time\n",
    "\n",
    "\n",
    "# %%\n",
    "def has_hard_contradiction(claim, relevant_chunks):\n",
    "    \"\"\"\n",
    "    Return True if we see a clear contradiction.\n",
    "    \"\"\"\n",
    "    if not is_absolute_claim(claim):\n",
    "        return False\n",
    "\n",
    "    for c in relevant_chunks:\n",
    "        text = c[\"text\"].lower()\n",
    "\n",
    "        # very simple signals of change or later action\n",
    "        if \"later\" in text or \"years later\" in text or \"afterward\" in text:\n",
    "            return True\n",
    "\n",
    "        if \"returned\" in text and \"never returned\" in claim.lower():\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "def has_event_contradiction(claim, relevant_chunks):\n",
    "    \"\"\"\n",
    "    Return True if the book strongly suggests\n",
    "    an incompatible event history.\n",
    "    \"\"\"\n",
    "    if not is_event_claim(claim):\n",
    "        return False\n",
    "\n",
    "    c = claim.lower()\n",
    "\n",
    "    for ch in relevant_chunks:\n",
    "        text = ch[\"text\"].lower()\n",
    "\n",
    "        # If claim implies a new arrest, but book says already imprisoned\n",
    "        if \"re-arrest\" in c or \"again\" in c:\n",
    "            if \"already imprisoned\" in text or \"had been imprisoned\" in text:\n",
    "                return True\n",
    "            if \"never released\" in text:\n",
    "                return True\n",
    "\n",
    "        # If claim says 'for life', but book mentions death shortly after\n",
    "        if \"for life\" in c:\n",
    "            if \"died\" in text or \"death\" in text:\n",
    "                return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "def sanitize_claims(claims):\n",
    "    clean = []\n",
    "\n",
    "    for c in claims:\n",
    "        c = c.strip()\n",
    "\n",
    "        # Reject very short fragments\n",
    "        if len(c) < 25:\n",
    "            continue\n",
    "\n",
    "        # Reject speculation / soft language\n",
    "        if any(w in c.lower() for w in [\n",
    "            \"might\", \"could\", \"possibly\", \"perhaps\", \"likely\"\n",
    "        ]):\n",
    "            continue\n",
    "\n",
    "        # Reject explanations\n",
    "        if any(w in c.lower() for w in [\n",
    "            \"because\", \"therefore\", \"suggests that\"\n",
    "        ]):\n",
    "            continue\n",
    "\n",
    "        clean.append(c)\n",
    "\n",
    "    return clean\n",
    "\n",
    "row = train.iloc[0]\n",
    "claims = split_claims(row[\"content\"])\n",
    "claim = claims[0]\n",
    "\n",
    "relevant_chunks = retrieve_chunks(\n",
    "    chunks=chunk_book(load_book(row[\"book_name\"])),\n",
    "    character=row[\"char\"],\n",
    "    claim=claim\n",
    ")\n",
    "\n",
    "def predict_backstory(row):\n",
    "    claims = split_claims(row[\"content\"])\n",
    "    book_text = load_book(row[\"book_name\"])\n",
    "    chunks = chunk_book(book_text)\n",
    "\n",
    "    for claim in claims:\n",
    "        relevant_chunks = retrieve_chunks(\n",
    "            chunks=chunks,\n",
    "            character=row[\"char\"],\n",
    "            claim=claim\n",
    "        )\n",
    "\n",
    "        # Rule 1: Absolute contradiction\n",
    "        if has_hard_contradiction(claim, relevant_chunks):\n",
    "            return 0\n",
    "\n",
    "        # Rule 2: Event-existence contradiction (NEW)\n",
    "        if has_event_contradiction(claim, relevant_chunks):\n",
    "            return 0\n",
    "\n",
    "    return 1\n",
    "\n",
    "correct = 0\n",
    "total = len(train)\n",
    "\n",
    "for _, row in train.iterrows():\n",
    "    pred = predict_backstory(row)\n",
    "    gold = 1 if row[\"label\"] == \"consistent\" else 0\n",
    "\n",
    "    if pred == gold:\n",
    "        correct += 1\n",
    "\n",
    "accuracy = correct / total\n",
    "print(\"TOTAL:\", total)\n",
    "print(\"CORRECT:\", correct)\n",
    "print(\"ACCURACY:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2026-01-11T17:03:00.686114Z",
     "iopub.status.busy": "2026-01-11T17:03:00.685789Z",
     "iopub.status.idle": "2026-01-11T17:09:09.616755Z",
     "shell.execute_reply": "2026-01-11T17:09:09.616080Z",
     "shell.execute_reply.started": "2026-01-11T17:03:00.686067Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "w_bdh:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "w_rule:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "w_rule:  20%|        | 1/5 [00:15<01:02, 15.61s/it]\u001b[A\n",
      "w_rule:  40%|      | 2/5 [00:30<00:46, 15.42s/it]\u001b[A\n",
      "w_rule:  60%|    | 3/5 [00:46<00:30, 15.34s/it]\u001b[A\n",
      "w_rule:  80%|  | 4/5 [01:01<00:15, 15.37s/it]\u001b[A\n",
      "w_rule: 100%|| 5/5 [01:17<00:00, 15.40s/it]\u001b[A\n",
      "w_bdh:  20%|        | 1/5 [01:17<05:08, 77.02s/it] \u001b[A\n",
      "w_rule:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "w_rule:  20%|        | 1/5 [00:14<00:59, 14.89s/it]\u001b[A\n",
      "w_rule:  40%|      | 2/5 [00:29<00:44, 14.75s/it]\u001b[A\n",
      "w_rule:  60%|    | 3/5 [00:44<00:29, 14.66s/it]\u001b[A\n",
      "w_rule:  80%|  | 4/5 [00:58<00:14, 14.63s/it]\u001b[A\n",
      "w_rule: 100%|| 5/5 [01:13<00:00, 14.58s/it]\u001b[A\n",
      "w_bdh:  40%|      | 2/5 [02:30<03:44, 74.76s/it] \u001b[A\n",
      "w_rule:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "w_rule:  20%|        | 1/5 [00:14<00:58, 14.62s/it]\u001b[A\n",
      "w_rule:  40%|      | 2/5 [00:29<00:43, 14.58s/it]\u001b[A\n",
      "w_rule:  60%|    | 3/5 [00:43<00:29, 14.57s/it]\u001b[A\n",
      "w_rule:  80%|  | 4/5 [00:58<00:14, 14.59s/it]\u001b[A\n",
      "w_rule: 100%|| 5/5 [01:12<00:00, 14.60s/it]\u001b[A\n",
      "w_bdh:  60%|    | 3/5 [03:43<02:27, 73.94s/it] \u001b[A\n",
      "w_rule:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "w_rule:  20%|        | 1/5 [00:14<00:58, 14.53s/it]\u001b[A\n",
      "w_rule:  40%|      | 2/5 [00:29<00:43, 14.56s/it]\u001b[A\n",
      "w_rule:  60%|    | 3/5 [00:43<00:29, 14.58s/it]\u001b[A\n",
      "w_rule:  80%|  | 4/5 [00:58<00:14, 14.57s/it]\u001b[A\n",
      "w_rule: 100%|| 5/5 [01:12<00:00, 14.59s/it]\u001b[A\n",
      "w_bdh:  80%|  | 4/5 [04:56<01:13, 73.54s/it] \u001b[A\n",
      "w_rule:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "w_rule:  20%|        | 1/5 [00:14<00:58, 14.50s/it]\u001b[A\n",
      "w_rule:  40%|      | 2/5 [00:28<00:43, 14.48s/it]\u001b[A\n",
      "w_rule:  60%|    | 3/5 [00:43<00:29, 14.54s/it]\u001b[A\n",
      "w_rule:  80%|  | 4/5 [00:58<00:14, 14.55s/it]\u001b[A\n",
      "w_rule: 100%|| 5/5 [01:12<00:00, 14.60s/it]\u001b[A\n",
      "w_bdh: 100%|| 5/5 [06:08<00:00, 73.78s/it] \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 5-Fold CV ensemble params:\n",
      "{'w_bdh': 0.6, 'w_rule': 0.4, 'threshold': 0.0, 'avg_f1': np.float64(0.769135334652576)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.metrics import f1_score\n",
    "# from tqdm import tqdm\n",
    "# import numpy as np\n",
    "\n",
    "# # Ground truth\n",
    "# y_true = train[\"label\"].map({\"consistent\":1, \"contradict\":0}).values\n",
    "\n",
    "# # Hyperparameter ranges\n",
    "# w_bdh_choices = [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "# w_rule_choices = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "# threshold_range = [0.0, 0.5, 1.0]\n",
    "\n",
    "# kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# best_avg_f1 = 0\n",
    "# best_params = {}\n",
    "\n",
    "# # Wrap hyperparameter grid with tqdm for progress\n",
    "# for w_bdh in tqdm(w_bdh_choices, desc=\"w_bdh\"):\n",
    "#     for w_rule in tqdm(w_rule_choices, desc=\"w_rule\", leave=False):\n",
    "#         for threshold in threshold_range:\n",
    "#             fold_f1 = []\n",
    "\n",
    "#             for train_idx, val_idx in kf.split(train):\n",
    "#                 val_preds = []\n",
    "#                 val_true = y_true[val_idx]\n",
    "\n",
    "#                 # Wrap validation fold with tqdm if you want\n",
    "#                 for idx in val_idx:\n",
    "#                     row = train.iloc[idx]\n",
    "\n",
    "#                     # BDH scoring\n",
    "#                     bdh_pred, bdh_score, _ = score_backstory_weighted(\n",
    "#                         row[\"book_name\"], row[\"content\"], top_k, sim_threshold, alpha, beta\n",
    "#                     )\n",
    "\n",
    "#                     # Rule-based scoring\n",
    "#                     rule_pred = predict_backstory(row)\n",
    "#                     rule_score = rule_pred\n",
    "\n",
    "#                     # Weighted ensemble\n",
    "#                     combined_score = w_bdh * bdh_score + w_rule * rule_score\n",
    "#                     final_pred = 1 if combined_score > threshold else 0\n",
    "#                     val_preds.append(final_pred)\n",
    "\n",
    "#                 val_preds = np.array(val_preds)\n",
    "#                 fold_f1.append(f1_score(val_true, val_preds))\n",
    "\n",
    "#             avg_f1 = np.mean(fold_f1)\n",
    "\n",
    "#             if avg_f1 > best_avg_f1:\n",
    "#                 best_avg_f1 = avg_f1\n",
    "#                 best_params = {\n",
    "#                     \"w_bdh\": w_bdh,\n",
    "#                     \"w_rule\": w_rule,\n",
    "#                     \"threshold\": threshold,\n",
    "#                     \"avg_f1\": avg_f1\n",
    "#                 }\n",
    "\n",
    "# print(\"Best 5-Fold CV ensemble params:\")\n",
    "# print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2026-01-11T17:18:40.612207Z",
     "iopub.status.busy": "2026-01-11T17:18:40.611630Z",
     "iopub.status.idle": "2026-01-11T17:18:40.616976Z",
     "shell.execute_reply": "2026-01-11T17:18:40.616363Z",
     "shell.execute_reply.started": "2026-01-11T17:18:40.612180Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#12\n",
    "def run_ensemble_inference(df, best_params, top_k, sim_threshold, alpha, beta):\n",
    "    preds = []\n",
    "\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        _, bdh_score, _ = score_backstory_weighted(\n",
    "            row[\"book_name\"], row[\"content\"],\n",
    "            top_k, sim_threshold, alpha, beta\n",
    "        )\n",
    "\n",
    "        rule_pred = predict_backstory(row)\n",
    "        rule_score = rule_pred\n",
    "\n",
    "        combined = (\n",
    "            best_params[\"w_bdh\"] * bdh_score +\n",
    "            best_params[\"w_rule\"] * rule_score\n",
    "        )\n",
    "\n",
    "        pred = 1 if combined > best_params[\"threshold\"] else 0\n",
    "        preds.append(pred)\n",
    "\n",
    "    return np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2026-01-11T17:18:40.771504Z",
     "iopub.status.busy": "2026-01-11T17:18:40.770850Z",
     "iopub.status.idle": "2026-01-11T17:18:45.720241Z",
     "shell.execute_reply": "2026-01-11T17:18:45.719410Z",
     "shell.execute_reply.started": "2026-01-11T17:18:40.771480Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 80/80 [00:04<00:00, 16.19it/s]\n"
     ]
    }
   ],
   "source": [
    "train_preds = run_ensemble_inference(train, best_params, top_k, sim_threshold, alpha, beta)\n",
    "# test_preds  = run_ensemble_inference(test,  best_params, top_k, sim_threshold, alpha, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2026-01-11T17:18:45.722071Z",
     "iopub.status.busy": "2026-01-11T17:18:45.721748Z",
     "iopub.status.idle": "2026-01-11T17:18:45.725734Z",
     "shell.execute_reply": "2026-01-11T17:18:45.724817Z",
     "shell.execute_reply.started": "2026-01-11T17:18:45.722045Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics as m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2026-01-11T17:18:45.727045Z",
     "iopub.status.busy": "2026-01-11T17:18:45.726818Z",
     "iopub.status.idle": "2026-01-11T17:18:45.745318Z",
     "shell.execute_reply": "2026-01-11T17:18:45.744616Z",
     "shell.execute_reply.started": "2026-01-11T17:18:45.727024Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0,\n",
       "       1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2026-01-11T17:18:45.746900Z",
     "iopub.status.busy": "2026-01-11T17:18:45.746671Z",
     "iopub.status.idle": "2026-01-11T17:18:45.760965Z",
     "shell.execute_reply": "2026-01-11T17:18:45.760151Z",
     "shell.execute_reply.started": "2026-01-11T17:18:45.746879Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2026-01-11T17:18:45.762609Z",
     "iopub.status.busy": "2026-01-11T17:18:45.761960Z",
     "iopub.status.idle": "2026-01-11T17:18:45.778870Z",
     "shell.execute_reply": "2026-01-11T17:18:45.778368Z",
     "shell.execute_reply.started": "2026-01-11T17:18:45.762585Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.accuracy_score(y_true, train_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 9236494,
     "sourceId": 14461033,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31234,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
